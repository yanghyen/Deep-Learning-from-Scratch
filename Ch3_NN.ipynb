{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d257f4d7",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "- 가중치 매개변수의 적절한 값을 데이터로 자동으로 학습하는 능력O\n",
    "### 활성화 함수\n",
    "- 입력 신호의 총합이 활성화를 일으키는지 정함\n",
    "- 층 쌓는 효과를 위해선 활성화 함수는 무조건 비선형 함수여야 함(선형함수는 제곱해도 의미 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de026c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b780e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return x \n",
    "#######################################\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0032779",
   "metadata": {},
   "source": [
    "### 다차원 배열의 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4275f489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([1,2,3,4])\n",
    "print(A)\n",
    "np.ndim(A)  # 차원수\n",
    "A.shape     # 1차원도 다차원과 통일된 형태로 반환하기 위해 튜플로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f8ec70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.array([[1,2],[3,4],[5,6]])\n",
    "print(B)\n",
    "np.ndim(B)\n",
    "B.shape     # 3x2 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87046c96",
   "metadata": {},
   "source": [
    "### 행렬곱\n",
    "- np.dot()\n",
    "    - np.dot(A, B)와 np.dot(B, A)는 다를 수 있음\n",
    "- 행렬끼리 차원수가 맞아야 함\n",
    "    - 3x2 • 2x4 = 3x4\n",
    "    - 3x2 • 2 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c34a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5 11 17]\n"
     ]
    }
   ],
   "source": [
    "# 신경망에서의 행렬 곱\n",
    "# X • W = Y\n",
    "# 2 • 2x3 = 3\n",
    "X = np.array([1, 2])\n",
    "W = np.array([[1, 3, 5], [2, 4, 6]])\n",
    "Y = np.dot(X, W)\n",
    "\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dee75c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "# 3층 신경망 구현\n",
    "def init_network():\n",
    "    network = {}\n",
    "    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])\n",
    "    network['b1'] = np.array([0.1, 0.2, 0.3])\n",
    "    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])\n",
    "    network['b2'] = np.array([0.1, 0.2])\n",
    "    network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])\n",
    "    network['b3'] = np.array([0.1, 0.2])\n",
    "\n",
    "    return network\n",
    "\n",
    "def identity_function(x): return x \n",
    "\n",
    "def forward(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = identity_function(a3)\n",
    "\n",
    "    return y \n",
    "\n",
    "network = init_network()\n",
    "x = np.array([1.0, 0.5])\n",
    "y = forward(network, x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee4d2f7",
   "metadata": {},
   "source": [
    "- 회귀: 항등 함수(identity function)\n",
    "- 분류: 소프트맥스 함수(softmax functin)\n",
    "    - 출력: 0~1 사이의 실수\n",
    "    - 출력 총합: 1\n",
    "    - 확률로 해석됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c523077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c)   # 오버플로를 막기 위함\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "\n",
    "    return y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e0a17f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 404 에러 떠서 url로 MNIST 받지 않고 keras에서 가져오겠듬\n",
    "\n",
    "### MNIST 데이터셋 활용해서 손글씨 숫자 인식\n",
    "# import sys, os\n",
    "# sys.path.append(os.path.join(os.getcwd(), \"data\"))\n",
    "# from data.mnist import load_mnist\n",
    "\n",
    "# (x_train, t_train), (x_test, t_test) = \\\n",
    "#     load_mnist(flatten = True, normalize = False)\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(t_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8d33367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hufs\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting setuptools (from tensorflow)\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hufs\\appdata\\roaming\\python\\python313\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting typing_extensions>=3.6.6 (from tensorflow)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.3-cp313-cp313-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.74.0-cp313-cp313-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\hufs\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tensorflow) (2.3.2)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.14.0-cp313-cp313-win_amd64.whl.metadata (2.7 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp313-cp313-win_amd64.whl.metadata (34 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hufs\\appdata\\roaming\\python\\python313\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl (332.0 MB)\n",
      "   ---------------------------------------- 0.0/332.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 16.0/332.0 MB 88.9 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 29.6/332.0 MB 73.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 53.7/332.0 MB 88.3 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 74.7/332.0 MB 91.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 99.9/332.0 MB 97.0 MB/s eta 0:00:03\n",
      "   -------------- ----------------------- 123.7/332.0 MB 100.4 MB/s eta 0:00:03\n",
      "   ---------------- ---------------------- 142.3/332.0 MB 98.8 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 164.4/332.0 MB 99.7 MB/s eta 0:00:02\n",
      "   ------------------- ------------------- 168.0/332.0 MB 93.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 171.7/332.0 MB 82.4 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 186.9/332.0 MB 81.2 MB/s eta 0:00:02\n",
      "   ----------------------- --------------- 197.1/332.0 MB 78.8 MB/s eta 0:00:02\n",
      "   ------------------------- ------------- 218.1/332.0 MB 81.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 222.6/332.0 MB 76.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 244.3/332.0 MB 78.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 268.2/332.0 MB 80.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 292.3/332.0 MB 83.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 315.9/332.0 MB 83.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 83.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/332.0 MB 83.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 332.0/332.0 MB 73.6 MB/s  0:00:04\n",
      "Downloading grpcio-1.74.0-cp313-cp313-win_amd64.whl (4.5 MB)\n",
      "   ---------------------------------------- 0.0/4.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.5/4.5 MB 92.8 MB/s  0:00:00\n",
      "Downloading ml_dtypes-0.5.3-cp313-cp313-win_amd64.whl (208 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 92.2 MB/s  0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp313-cp313-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/2.9 MB 83.0 MB/s  0:00:00\n",
      "Downloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 85.1 MB/s  0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 9.2/26.4 MB 42.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 65.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 60.7 MB/s  0:00:00\n",
      "Downloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 61.9 MB/s  0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading wrapt-1.17.3-cp313-cp313-win_amd64.whl (38 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp313-cp313-win_amd64.whl (316 kB)\n",
      "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 7.0/7.0 MB 102.5 MB/s  0:00:00\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, typing_extensions, termcolor, tensorboard-data-server, setuptools, protobuf, pillow, opt_einsum, ml_dtypes, mdurl, MarkupSafe, markdown, idna, h5py, grpcio, google_pasta, gast, charset_normalizer, certifi, absl-py, werkzeug, requests, optree, markdown-it-py, astunparse, tensorboard, rich, keras, tensorflow\n",
      "\n",
      "   - --------------------------------------  1/34 [libclang]\n",
      "   - --------------------------------------  1/34 [libclang]\n",
      "   -- -------------------------------------  2/34 [flatbuffers]\n",
      "   ---- -----------------------------------  4/34 [wheel]\n",
      "   ---- -----------------------------------  4/34 [wheel]\n",
      "   ---- -----------------------------------  4/34 [wheel]\n",
      "   ----- ----------------------------------  5/34 [urllib3]\n",
      "   ----- ----------------------------------  5/34 [urllib3]\n",
      "   ----- ----------------------------------  5/34 [urllib3]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ---------- -----------------------------  9/34 [setuptools]\n",
      "   ----------- ---------------------------- 10/34 [protobuf]\n",
      "   ----------- ---------------------------- 10/34 [protobuf]\n",
      "   ----------- ---------------------------- 10/34 [protobuf]\n",
      "   ----------- ---------------------------- 10/34 [protobuf]\n",
      "   ------------ --------------------------- 11/34 [pillow]\n",
      "   ------------ --------------------------- 11/34 [pillow]\n",
      "   ------------ --------------------------- 11/34 [pillow]\n",
      "   ------------ --------------------------- 11/34 [pillow]\n",
      "   ------------ --------------------------- 11/34 [pillow]\n",
      "   ------------ --------------------------- 11/34 [pillow]\n",
      "   ------------ --------------------------- 11/34 [pillow]\n",
      "   ------------ --------------------------- 11/34 [pillow]\n",
      "   -------------- ------------------------- 12/34 [opt_einsum]\n",
      "   -------------- ------------------------- 12/34 [opt_einsum]\n",
      "   ---------------- ----------------------- 14/34 [mdurl]\n",
      "   ------------------ --------------------- 16/34 [markdown]\n",
      "   ------------------ --------------------- 16/34 [markdown]\n",
      "   ------------------ --------------------- 16/34 [markdown]\n",
      "   -------------------- ------------------- 17/34 [idna]\n",
      "   --------------------- ------------------ 18/34 [h5py]\n",
      "   --------------------- ------------------ 18/34 [h5py]\n",
      "   --------------------- ------------------ 18/34 [h5py]\n",
      "   --------------------- ------------------ 18/34 [h5py]\n",
      "   --------------------- ------------------ 18/34 [h5py]\n",
      "   ---------------------- ----------------- 19/34 [grpcio]\n",
      "   ---------------------- ----------------- 19/34 [grpcio]\n",
      "   ---------------------- ----------------- 19/34 [grpcio]\n",
      "   ---------------------- ----------------- 19/34 [grpcio]\n",
      "   ----------------------- ---------------- 20/34 [google_pasta]\n",
      "   ------------------------ --------------- 21/34 [gast]\n",
      "   ------------------------- -------------- 22/34 [charset_normalizer]\n",
      "   --------------------------- ------------ 23/34 [certifi]\n",
      "   ---------------------------- ----------- 24/34 [absl-py]\n",
      "   ---------------------------- ----------- 24/34 [absl-py]\n",
      "   ----------------------------- ---------- 25/34 [werkzeug]\n",
      "   ----------------------------- ---------- 25/34 [werkzeug]\n",
      "   ----------------------------- ---------- 25/34 [werkzeug]\n",
      "   ----------------------------- ---------- 25/34 [werkzeug]\n",
      "   ------------------------------ --------- 26/34 [requests]\n",
      "   ------------------------------- -------- 27/34 [optree]\n",
      "   ------------------------------- -------- 27/34 [optree]\n",
      "   -------------------------------- ------- 28/34 [markdown-it-py]\n",
      "   -------------------------------- ------- 28/34 [markdown-it-py]\n",
      "   -------------------------------- ------- 28/34 [markdown-it-py]\n",
      "   -------------------------------- ------- 28/34 [markdown-it-py]\n",
      "   ---------------------------------- ----- 29/34 [astunparse]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ----------------------------------- ---- 30/34 [tensorboard]\n",
      "   ------------------------------------ --- 31/34 [rich]\n",
      "   ------------------------------------ --- 31/34 [rich]\n",
      "   ------------------------------------ --- 31/34 [rich]\n",
      "   ------------------------------------ --- 31/34 [rich]\n",
      "   ------------------------------------ --- 31/34 [rich]\n",
      "   ------------------------------------ --- 31/34 [rich]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   ------------------------------------- -- 32/34 [keras]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   -------------------------------------- - 33/34 [tensorflow]\n",
      "   ---------------------------------------- 34/34 [tensorflow]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.3.1 astunparse-1.6.3 certifi-2025.8.3 charset_normalizer-3.4.3 flatbuffers-25.2.10 gast-0.6.0 google_pasta-0.2.0 grpcio-1.74.0 h5py-3.14.0 idna-3.10 keras-3.11.3 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 pillow-11.3.0 protobuf-6.32.1 requests-2.32.5 rich-14.1.0 setuptools-80.9.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 typing_extensions-4.15.0 urllib3-2.5.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f32a7a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n",
      "(10000, 784) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test  = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "print(x_train.shape, t_train.shape)\n",
    "print(x_test.shape, t_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "170d2eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.6-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.2-cp313-cp313-win_amd64.whl.metadata (111 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp313-cp313-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\hufs\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hufs\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hufs\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.4-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hufs\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hufs\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.6-cp313-cp313-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 8.1/8.1 MB 53.8 MB/s  0:00:00\n",
      "Downloading contourpy-1.3.3-cp313-cp313-win_amd64.whl (226 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.2-cp313-cp313-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.3/2.3 MB 85.4 MB/s  0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp313-cp313-win_amd64.whl (73 kB)\n",
      "Downloading pyparsing-3.2.4-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\n",
      "   ---------------------------------------- 0/6 [pyparsing]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   ------------- -------------------------- 2/6 [fonttools]\n",
      "   -------------------------- ------------- 4/6 [contourpy]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   --------------------------------- ------ 5/6 [matplotlib]\n",
      "   ---------------------------------------- 6/6 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.2 kiwisolver-1.4.9 matplotlib-3.10.6 pyparsing-3.2.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73c1e776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터: (60000, 28, 28) (60000,)\n",
      "테스트 데이터: (10000, 28, 28) (10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# MNIST 데이터 불러오기\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"훈련 데이터:\", x_train.shape, y_train.shape)\n",
    "print(\"테스트 데이터:\", x_test.shape, y_test.shape)\n",
    "\n",
    "# 첫번째 이미지 보기\n",
    "plt.imshow(x_train[0], cmap='gray')\n",
    "plt.title(f\"Label: {y_train[0]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a77559",
   "metadata": {},
   "source": [
    "### 신경망의 추론 처리\n",
    "- 입력층 뉴런 784개, 출력층 뉴런 10개로 구성\n",
    "    - 이미지 크기가 28*28 = 784\n",
    "    - 0~9의 숫자를 구분하는 거라 10개\n",
    "- 은닉층은 두개\n",
    "    1. 50개 뉴런\n",
    "    2. 100개 뉴런\n",
    "    - 50개와 100개는 임의로 정한 값 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95bb4aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\n",
      "ERROR: No matching distribution found for pickle\n"
     ]
    }
   ],
   "source": [
    "%pip install pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea325410",
   "metadata": {},
   "source": [
    "- sample_weight.pkl에 저장된 학습된 가중치 매개변수를 읽어옴\n",
    "- 이 파일에는 가중치와 편향 매개변수가 딕셔너리 변수로 저장돼있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f2f8698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = mnist.load_data()\n",
    "    \n",
    "    # flatten\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "    x_test  = x_test.reshape(x_test.shape[0], -1)\n",
    "    return x_test, t_test\n",
    "\n",
    "def init_network():\n",
    "    with open(\"sample_weight.pkl\", \"rb\") as f:\n",
    "        network = pickle.load(f)\n",
    "\n",
    "    return network\n",
    "\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "\n",
    "    return y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c221d466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
